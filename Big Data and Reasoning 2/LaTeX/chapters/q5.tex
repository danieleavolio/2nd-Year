\section{Domande: MapReduce Introduction}
\begin{domanda}
    Per quale motivo Google ha inventato Map Reduce?
\end{domanda}

Perche' aveva bisogno di un sistema che permettesse il processamento di un
quantitativo enorme di file tra diverse macchine, in modo parallelo, con una
tolleranza ai guasti e senza usare codici troppo complessi. Per questo motivo,
nasce questo sistema che permette di fare tutto cio'. Ah questo andava fatto
pero' su diverse macchine che non costassero un patrimonio, quindi doveva
essere anche economico.

\begin{quote}
    I programmatori che non erano esperti di programmazione distribuita dovevano essere in grado di effettuare operazioni su sistema distribuiti a larga scala.
\end{quote}

\begin{domanda}
    Cos'e' MapReduce
\end{domanda}

MapReduce e' un modello di programmazione che soddisfa i seguenti punti:
\begin{itemize}
    \item Programma per processare grandi insiemi di dati 
    \item Partizionare i dati di input 
    \item Schedulare l'esecuzione su un cluster di macchine
    \item Gestire i guasti
    \item Gestire la comunicazione tra le macchine
\end{itemize}

\begin{domanda}
    Quali sono i componenti principali di MapReduce
\end{domanda}

I principali componenti di MapReduce sono due funzioni:
\begin{itemize}
    \item Funzione mapping
    \item Funzione reducing
\end{itemize}

\[
  map(k1,v1) \rightarrow list(k2,v2)
\]
Prende in \textbf{input} una coppia chiave valore e restituisce in \textbf{output} una lista di
coppie chiave valore.
\[
  reduce(k2,list(v2)) \rightarrow list(v2)
\]
Prende in \textbf{input} una chiave e una lista di valori e restituisce in \textbf{output} una lista di
valori. (Oppure una coppia chiave valore)

Praticamente il workflow e':
\begin{enumerate}
    \item Map: Si prende un file e lo si divide in blocchi
    \item Map: Si applica la funzione map a tutti i blocchi
    \item I risultati vengono salvati sulle macchine locali 
    \item Reduce: Si prendono i risultati e si applica la funzione reduce
    \item Reduce: Si salvano i risultati finali sul GFS o HDFS
\end{enumerate}

\begin{lstlisting}[language=java][caption=MapReduce in Java]
    map(String key, String value):
        // key: document name
        // value: document contents
        for each word w in value:
            EmitIntermediate(w, "1");
    
    reduce(String key, Iterator values):
        // key: a word
        // values: a list of counts
        int result = 0;
        for each v in values:
            result += ParseInt(v);
        Emit(AsString(result));
\end{lstlisting}


\begin{domanda}
    Cosa succede in questo caso se il file per word count ha solamente 1 parola ripetuta 1000 volte?
\end{domanda}

In questo caso, il lavoro del mapping sara' super parallelo, ma il lavoro 
del reducing sara' sequenziale, perche' tutti i risultati del mapping
verranno mandati al reducer che si occupera' di fare il reduce.

\begin{domanda}
    La fase di shuffle cosa fa?
\end{domanda}

La fase di shuffle e' la fase che si occupa di \textbf{mandare i risultati del mapping
al reducer corretto}. In questo caso, il reducer corretto e' quello che si occupa
di fare il reduce della parola che e' stata mappata.


\begin{domanda}
    Workflow di ma reduce nel dettaglio
\end{domanda}

\begin{enumerate}
    \item Viene splittato il file di input in diversi file 
    \item Si passa il programma al cluster di macchine
    \item La macchina master divide il lavoro tra i worker
    \item Ci sono $M$ task di mapping e $R$ task di reducing
    \item I worker leggono il contenuto del file di input assegnato dal master
    \begin{itemize}
        \item Per ogni coppia chiave valore, viene applicata la funzione map
        \item Le coppie vengono salvate nella memoria buffer
        \item I risultati vengono salvati in memoria locale periodicamente leggendo dalla memoria buffer in $R$ regioni.
    \end{itemize}
    \item Il master viene informato di dove sono queste $R$ regioni
    \item Manda le informazioni sulla regione ai reducer
    \item I reducer leggono i risultati dal disco locale tramite procedure remote 
    \begin{itemize}
        \item I risultati vengono ordinati per chiave
        \item I risultati vengono passati alla funzione reduce
        \item I risultati vengono aggiunti alla fine del file output (\textit{appending})
    \end{itemize}
    \item Tutte le macchine comunicano con il master che hanno terminato il lavoro
    \item Il master manda il segnale di terminazione al client
    \item Il file output e' disponibile per il client
\end{enumerate}

\begin{domanda}
    Come fa MapReduce ad essere fault tolerant?
\end{domanda}

Dobbiamo dire innanzitutto che abbiamo due tipi di fallimenti:
\begin{itemize}
    \item Worker Failure
    \item Master Failure
\end{itemize}

\textbf{Worker Failure}: Il master tenta di tanto in tanto di pingare il worker. Se esso non risponde entro un certo limite di tempo, allora il master \textbf{segna il worker come inattivo}, e quindi questo implica che:
\begin{itemize}
    \item Le task che dovevano essere eseguite dal worker e anche quelle gia completate vengono riassegnate ad altri worker
    \item Le task gia completate vengono eseguite dinuovo da altri worker: questo perche' ogni worker scrive sulla memoria locale, e quei file sono ormai perduti e non piu accessibili
    \item Discorso diverso se il worker era un \textbf{reducer}: Se il reducer ha gia' completato il suo lavoro ma non risponde, la sua task non va riassegnata perche' ha gia' inserito l'output della funzione reduce nel file di output corretto, che e' disponbiile sul filesystem.
\end{itemize}

\textbf{Master Failure}: Se il master fallisce gli facciamo il funerale. Si ferma la computazione di MapReduce.

\begin{domanda}
    Spiega la locality di MapReduce
\end{domanda}

In MapReduce si vuole risparmiare banda piu' che si puo'. 
Per questo motivo, i file hanno un fattore di replicazione che dipende dalla configurazione del cluster.
I dati iniziali vengono salvati su dischi locali delle macchine e in multipla copia.

Quando viene \textbf{assegnato un task di map}, si tende ad assegnarlo alle macchine che hanno i file \textit{vicini} oppure gia' salvati all'interno della propria memoria come copia. Questo minimizza il consumo di banda.

\begin{domanda}
    Spiega la task granularity di MapReduce
\end{domanda}

Diciamo che MapReduce tende a scegliere un numero di Mappers $M$ 
tale che ogni compito di mapping richieda circa 16-64 MB di input.

Sceglie $R$ un piccolo multiplo delle macchine del cluster, per bilanciarne il carico. 

Sceglie il numero di $M$ e $R$ in modo che siano molto piu' grandi del numero di macchine nel cluster.

\begin{domanda}
    Spiega backup tasks in MapReduce
\end{domanda}

Allevia il problema dei \textbf{ritardatari} o stragglers. 
Cioe', il master schedula delle esecuzioni backup delle task in corso. La task viene segnata come completa 
indipendentemente dal fatto che la task originale sia completata o meno. Cioe' la cosa che
gli interessa di piu' e' che la task sia completata da qualche worker. 

\newpage