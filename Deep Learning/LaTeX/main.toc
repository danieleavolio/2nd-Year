\contentsline {section}{\numberline {1}Introduzione}{5}{section.1}%
\contentsline {section}{\numberline {2}Deep Learning 101}{5}{section.2}%
\contentsline {subsection}{\numberline {2.1}Architetture e strumenti nel deep learning}{5}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Libri utili}{5}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}Strumenti che useremo}{6}{subsection.2.3}%
\contentsline {subsection}{\numberline {2.4}Schema generale di un problema di deep learning}{6}{subsection.2.4}%
\contentsline {subsection}{\numberline {2.5}Perch√© si usa il termine "Tensore"?}{6}{subsection.2.5}%
\contentsline {subsection}{\numberline {2.6}AI vs DL}{7}{subsection.2.6}%
\contentsline {section}{\numberline {3}Introduzione alle Reti Neurali}{8}{section.3}%
\contentsline {subsection}{\numberline {3.1}Il modello di McCulloch-Pitts}{8}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Modello di Rosenblatt}{8}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Esempio con 2 neuroni}{9}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}Rappresentazione le funzioni logiche}{10}{subsection.3.4}%
\contentsline {subsubsection}{\numberline {3.4.1}AND}{10}{subsubsection.3.4.1}%
\contentsline {subsubsection}{\numberline {3.4.2}Il problema dello XOR}{11}{subsubsection.3.4.2}%
\contentsline {subsection}{\numberline {3.5}Gli ingredienti di una rete neurale}{12}{subsection.3.5}%
\contentsline {subsubsection}{\numberline {3.5.1}Il grafo g}{12}{subsubsection.3.5.1}%
\contentsline {subsubsection}{\numberline {3.5.2}La funzione di loss}{13}{subsubsection.3.5.2}%
\contentsline {subsubsection}{\numberline {3.5.3}Funzione di loss per Regressione}{14}{subsubsection.3.5.3}%
\contentsline {subsubsection}{\numberline {3.5.4}Funzione di loss per classificazione}{14}{subsubsection.3.5.4}%
\contentsline {subsection}{\numberline {3.6}L'ottimizzatore o}{14}{subsection.3.6}%
\contentsline {subsubsection}{\numberline {3.6.1}Il metodo di discesa del gradiente}{15}{subsubsection.3.6.1}%
\contentsline {subsubsection}{\numberline {3.6.2}Il metodo di discesa del gradiente stocastico}{16}{subsubsection.3.6.2}%
\contentsline {subsubsection}{\numberline {3.6.3}Linee guida sul learning rate}{17}{subsubsection.3.6.3}%
\contentsline {section}{\numberline {4}Classificazione Binaria}{19}{section.4}%
\contentsline {subsection}{\numberline {4.1}Caricamento e gestione del Dataset}{20}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Definizione della Rete Neurale}{21}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Plotting del modello}{23}{subsection.4.3}%
\contentsline {subsection}{\numberline {4.4}Training del modello e valutazione}{24}{subsection.4.4}%
\contentsline {subsubsection}{\numberline {4.4.1}Validation Set}{24}{subsubsection.4.4.1}%
\contentsline {subsection}{\numberline {4.5}Prediction}{28}{subsection.4.5}%
\contentsline {subsection}{\numberline {4.6}Come risolvere problemi di accuracy bassa?}{28}{subsection.4.6}%
\contentsline {subsection}{\numberline {4.7}Early Stopping}{29}{subsection.4.7}%
\contentsline {section}{\numberline {5}Classificazione Multiclasse}{29}{section.5}%
\contentsline {subsection}{\numberline {5.1}Descrizione del dataset - Reuters}{29}{subsection.5.1}%
\contentsline {subsubsection}{\numberline {5.1.1}Come processiamo l'output?}{29}{subsubsection.5.1.1}%
\contentsline {subsubsection}{\numberline {5.1.2}Softmax activation function}{30}{subsubsection.5.1.2}%
\contentsline {section}{\numberline {6}Regressione}{32}{section.6}%
\contentsline {subsection}{\numberline {6.1}Boston Housing Price}{32}{subsection.6.1}%
\contentsline {subsubsection}{\numberline {6.1.1}Normalizzare i dati}{32}{subsubsection.6.1.1}%
\contentsline {subsubsection}{\numberline {6.1.2}Costruzione della rete}{33}{subsubsection.6.1.2}%
\contentsline {subsubsection}{\numberline {6.1.3}Validation con pochi data point}{33}{subsubsection.6.1.3}%
\contentsline {subsubsection}{\numberline {6.1.4}Visualizzare i risultati}{34}{subsubsection.6.1.4}%
\contentsline {subsection}{\numberline {6.2}Overfitting}{34}{subsection.6.2}%
\contentsline {subsubsection}{\numberline {6.2.1}Regolarizzazione}{34}{subsubsection.6.2.1}%
\contentsline {subsection}{\numberline {6.3}Dropout}{36}{subsection.6.3}%
\contentsline {section}{\numberline {7}Convolutional Neural Networks}{37}{section.7}%
\contentsline {subsection}{\numberline {7.1}Il primo problema con le immagini}{37}{subsection.7.1}%
\contentsline {subsection}{\numberline {7.2}Il secondo problema}{37}{subsection.7.2}%
\contentsline {subsection}{\numberline {7.3}Come fa la rete a riconoscere i pattern}{37}{subsection.7.3}%
\contentsline {subsection}{\numberline {7.4}Convoluzione}{38}{subsection.7.4}%
\contentsline {subsection}{\numberline {7.5}Padding}{39}{subsection.7.5}%
\contentsline {subsection}{\numberline {7.6}Strides}{39}{subsection.7.6}%
\contentsline {subsection}{\numberline {7.7}Esempio 1}{39}{subsection.7.7}%
\contentsline {subsection}{\numberline {7.8}Pooling}{40}{subsection.7.8}%
\contentsline {subsubsection}{\numberline {7.8.1}Max Pooling}{40}{subsubsection.7.8.1}%
\contentsline {subsection}{\numberline {7.9}Multiclass Classification Example}{41}{subsection.7.9}%
\contentsline {subsection}{\numberline {7.10}Nozioni alla lavagna}{42}{subsection.7.10}%
\contentsline {section}{\numberline {8}Reti Neurali Convoluzionali Pre-allenate}{43}{section.8}%
\contentsline {subsection}{\numberline {8.1}Come si usa il transfer learning?}{43}{subsection.8.1}%
\contentsline {section}{\numberline {9}Oltre il modello sequenziale}{45}{section.9}%
\contentsline {subsection}{\numberline {9.1}Multi input e multi output}{45}{subsection.9.1}%
\contentsline {subsection}{\numberline {9.2}Functional API}{45}{subsection.9.2}%
\contentsline {section}{\numberline {10}Adanvced Keras}{47}{section.10}%
\contentsline {subsection}{\numberline {10.1}Subclassing}{47}{subsection.10.1}%
\contentsline {section}{\numberline {11}Serie Temporali | Time Series}{48}{section.11}%
\contentsline {subsection}{\numberline {11.1}Recurrent Neural Network RNN}{48}{subsection.11.1}%
\contentsline {subsubsection}{\numberline {11.1.1}L'utilizzo delle RNN}{49}{subsubsection.11.1.1}%
\contentsline {subsection}{\numberline {11.2}Long Short Term Memory (LSTM)}{51}{subsection.11.2}%
\contentsline {section}{\numberline {12}Lab: Introduzione Python}{55}{section.12}%
\contentsline {subsection}{\numberline {12.1}MatPlotLib}{55}{subsection.12.1}%
\contentsline {subsubsection}{\numberline {12.1.1}Plots}{55}{subsubsection.12.1.1}%
\contentsline {subsubsection}{\numberline {12.1.2}Sub-plots}{55}{subsubsection.12.1.2}%
\contentsline {subsection}{\numberline {12.2}NumPy}{56}{subsection.12.2}%
\contentsline {section}{\numberline {13}Lab: Reti Neurali da zero}{58}{section.13}%
\contentsline {subsection}{\numberline {13.1}Introduzione}{58}{subsection.13.1}%
\contentsline {subsection}{\numberline {13.2}Esempio pratico}{58}{subsection.13.2}%
\contentsline {subsubsection}{\numberline {13.2.1}Il grafo}{59}{subsubsection.13.2.1}%
\contentsline {subsubsection}{\numberline {13.2.2}La funnzione loss}{59}{subsubsection.13.2.2}%
\contentsline {subsubsection}{\numberline {13.2.3}L'ottimizzatore}{60}{subsubsection.13.2.3}%
\contentsline {subsubsection}{\numberline {13.2.4}Discesa del gradiente}{60}{subsubsection.13.2.4}%
\contentsline {subsubsection}{\numberline {13.2.5}Inizializzatore}{60}{subsubsection.13.2.5}%
\contentsline {subsubsection}{\numberline {13.2.6}Fix Point Procedure}{60}{subsubsection.13.2.6}%
\contentsline {subsection}{\numberline {13.3}Esempio da zero}{60}{subsection.13.3}%
\contentsline {subsubsection}{\numberline {13.3.1}La funzione Sigmoid}{60}{subsubsection.13.3.1}%
\contentsline {subsection}{\numberline {13.4}Tangente Iperbolica TanH}{61}{subsection.13.4}%
\contentsline {subsection}{\numberline {13.5}ReLu}{62}{subsection.13.5}%
\contentsline {subsection}{\numberline {13.6}Scalare i valori}{63}{subsection.13.6}%
\contentsline {subsection}{\numberline {13.7}Plottare la loss}{64}{subsection.13.7}%
\contentsline {subsection}{\numberline {13.8}Importante cosa su Gradient Descent}{65}{subsection.13.8}%
\contentsline {section}{\numberline {14}TensorFlow e Keras}{66}{section.14}%
\contentsline {subsection}{\numberline {14.1}One Hot Encoding}{66}{subsection.14.1}%
\contentsline {subsection}{\numberline {14.2}Variabili correlate}{66}{subsection.14.2}%
\contentsline {subsection}{\numberline {14.3}Accuracy come loss}{66}{subsection.14.3}%
\contentsline {subsection}{\numberline {14.4}Epoche e batch size}{66}{subsection.14.4}%
\contentsline {subsection}{\numberline {14.5}Overfitting e come evitarlo}{67}{subsection.14.5}%
\contentsline {subsection}{\numberline {14.6}Migliorare le performance di un modello}{67}{subsection.14.6}%
\contentsline {section}{\numberline {15}Lab: Convolutional Neural Networks}{68}{section.15}%
\contentsline {subsection}{\numberline {15.1}Cross Entropy vs Accuracy}{68}{subsection.15.1}%
\contentsline {subsection}{\numberline {15.2}Workflow per image classification}{69}{subsection.15.2}%
\contentsline {subsubsection}{\numberline {15.2.1}Bilanciare le classi}{69}{subsubsection.15.2.1}%
\contentsline {section}{\numberline {16}Autoencoders}{71}{section.16}%
\contentsline {subsection}{\numberline {16.1}Nota su PCA}{71}{subsection.16.1}%
\contentsline {subsection}{\numberline {16.2}Autoencoders}{71}{subsection.16.2}%
\contentsline {subsubsection}{\numberline {16.2.1}Gli steps}{72}{subsubsection.16.2.1}%
\contentsline {subsubsection}{\numberline {16.2.2}Applicazioni}{72}{subsubsection.16.2.2}%
\contentsline {subsection}{\numberline {16.3}Autoencoders e Convolution}{73}{subsection.16.3}%
\contentsline {section}{\numberline {17}VAE (Variational Autoencoder)}{74}{section.17}%
\contentsline {subsection}{\numberline {17.1}Regularization term e Reparametrization trick}{75}{subsection.17.1}%
\contentsline {section}{\numberline {18}Recurrent Neural Network e Natural Language Processing (RNN e NLP)}{78}{section.18}%
\contentsline {subsection}{\numberline {18.1}RNN e LSTM}{78}{subsection.18.1}%
\contentsline {subsection}{\numberline {18.2}NLP}{80}{subsection.18.2}%
\contentsline {subsection}{\numberline {18.3}Come si lavora con i Word Embedding?}{80}{subsection.18.3}%
\contentsline {subsubsection}{\numberline {18.3.1}Encoder}{80}{subsubsection.18.3.1}%
