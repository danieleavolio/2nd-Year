\contentsline {section}{\numberline {1}Introduzione}{4}{section.1}%
\contentsline {section}{\numberline {2}Deep Learning 101}{4}{section.2}%
\contentsline {subsection}{\numberline {2.1}Architetture e strumenti nel deep learning}{4}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Libri utili}{4}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}Strumenti che useremo}{5}{subsection.2.3}%
\contentsline {subsection}{\numberline {2.4}Schema generale di un problema di deep learning}{5}{subsection.2.4}%
\contentsline {subsection}{\numberline {2.5}Perch√© si usa il termine "Tensore"?}{5}{subsection.2.5}%
\contentsline {subsection}{\numberline {2.6}AI vs DL}{6}{subsection.2.6}%
\contentsline {section}{\numberline {3}Introduzione alle Reti Neurali}{7}{section.3}%
\contentsline {subsection}{\numberline {3.1}Il modello di McCulloch-Pitts}{7}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Modello di Rosenblatt}{7}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Esempio con 2 neuroni}{8}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}Rappresentazione le funzioni logiche}{9}{subsection.3.4}%
\contentsline {subsubsection}{\numberline {3.4.1}AND}{9}{subsubsection.3.4.1}%
\contentsline {subsubsection}{\numberline {3.4.2}Il problema dello XOR}{10}{subsubsection.3.4.2}%
\contentsline {subsection}{\numberline {3.5}Gli ingredienti di una rete neurale}{11}{subsection.3.5}%
\contentsline {subsubsection}{\numberline {3.5.1}Il grafo g}{11}{subsubsection.3.5.1}%
\contentsline {subsubsection}{\numberline {3.5.2}La funzione di loss}{12}{subsubsection.3.5.2}%
\contentsline {subsubsection}{\numberline {3.5.3}Funzione di loss per Regressione}{13}{subsubsection.3.5.3}%
\contentsline {subsubsection}{\numberline {3.5.4}Funzione di loss per classificazione}{13}{subsubsection.3.5.4}%
\contentsline {subsection}{\numberline {3.6}L'ottimizzatore o}{13}{subsection.3.6}%
\contentsline {subsubsection}{\numberline {3.6.1}Il metodo di discesa del gradiente}{14}{subsubsection.3.6.1}%
\contentsline {subsubsection}{\numberline {3.6.2}Il metodo di discesa del gradiente stocastico}{15}{subsubsection.3.6.2}%
\contentsline {subsubsection}{\numberline {3.6.3}Linee guida sul learning rate}{16}{subsubsection.3.6.3}%
\contentsline {section}{\numberline {4}Classificazione Binaria}{18}{section.4}%
\contentsline {subsection}{\numberline {4.1}Caricamento e gestione del Dataset}{19}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Definizione della Rete Neurale}{20}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Plotting del modello}{22}{subsection.4.3}%
\contentsline {subsection}{\numberline {4.4}Training del modello e valutazione}{23}{subsection.4.4}%
\contentsline {subsubsection}{\numberline {4.4.1}Validation Set}{23}{subsubsection.4.4.1}%
\contentsline {subsection}{\numberline {4.5}Prediction}{27}{subsection.4.5}%
\contentsline {subsection}{\numberline {4.6}Come risolvere problemi di accuracy bassa?}{27}{subsection.4.6}%
\contentsline {subsection}{\numberline {4.7}Early Stopping}{28}{subsection.4.7}%
\contentsline {section}{\numberline {5}Classificazione Multiclasse}{28}{section.5}%
\contentsline {subsection}{\numberline {5.1}Descrizione del dataset - Reuters}{28}{subsection.5.1}%
\contentsline {subsubsection}{\numberline {5.1.1}Come processiamo l'output?}{28}{subsubsection.5.1.1}%
\contentsline {subsubsection}{\numberline {5.1.2}Softmax activation function}{29}{subsubsection.5.1.2}%
\contentsline {section}{\numberline {6}Regressione}{31}{section.6}%
\contentsline {subsection}{\numberline {6.1}Boston Housing Price}{31}{subsection.6.1}%
\contentsline {subsubsection}{\numberline {6.1.1}Normalizzare i dati}{31}{subsubsection.6.1.1}%
\contentsline {subsubsection}{\numberline {6.1.2}Costruzione della rete}{32}{subsubsection.6.1.2}%
\contentsline {subsubsection}{\numberline {6.1.3}Validation con pochi data point}{32}{subsubsection.6.1.3}%
\contentsline {subsubsection}{\numberline {6.1.4}Visualizzare i risultati}{33}{subsubsection.6.1.4}%
\contentsline {subsection}{\numberline {6.2}Overfitting}{33}{subsection.6.2}%
\contentsline {subsubsection}{\numberline {6.2.1}Regolarizzazione}{33}{subsubsection.6.2.1}%
\contentsline {subsection}{\numberline {6.3}Dropout}{35}{subsection.6.3}%
\contentsline {section}{\numberline {7}Lab: Introduzione Python}{36}{section.7}%
\contentsline {subsection}{\numberline {7.1}MatPlotLib}{36}{subsection.7.1}%
\contentsline {subsubsection}{\numberline {7.1.1}Plots}{36}{subsubsection.7.1.1}%
\contentsline {subsubsection}{\numberline {7.1.2}Sub-plots}{36}{subsubsection.7.1.2}%
\contentsline {subsection}{\numberline {7.2}NumPy}{37}{subsection.7.2}%
\contentsline {section}{\numberline {8}Lab: Reti Neurali da zero}{39}{section.8}%
\contentsline {subsection}{\numberline {8.1}Introduzione}{39}{subsection.8.1}%
\contentsline {subsection}{\numberline {8.2}Esempio pratico}{39}{subsection.8.2}%
\contentsline {subsubsection}{\numberline {8.2.1}Il grafo}{40}{subsubsection.8.2.1}%
\contentsline {subsubsection}{\numberline {8.2.2}La funnzione loss}{40}{subsubsection.8.2.2}%
\contentsline {subsubsection}{\numberline {8.2.3}L'ottimizzatore}{41}{subsubsection.8.2.3}%
\contentsline {subsubsection}{\numberline {8.2.4}Discesa del gradiente}{41}{subsubsection.8.2.4}%
\contentsline {subsubsection}{\numberline {8.2.5}Inizializzatore}{41}{subsubsection.8.2.5}%
\contentsline {subsubsection}{\numberline {8.2.6}Fix Point Procedure}{41}{subsubsection.8.2.6}%
\contentsline {subsection}{\numberline {8.3}Esempio da zero}{41}{subsection.8.3}%
\contentsline {subsubsection}{\numberline {8.3.1}La funzione Sigmoid}{41}{subsubsection.8.3.1}%
\contentsline {subsection}{\numberline {8.4}Tangente Iperbolica TanH}{42}{subsection.8.4}%
\contentsline {subsection}{\numberline {8.5}ReLu}{43}{subsection.8.5}%
\contentsline {subsection}{\numberline {8.6}Scalare i valori}{44}{subsection.8.6}%
\contentsline {subsection}{\numberline {8.7}Plottare la loss}{45}{subsection.8.7}%
