\section{Lab: Convolutional Neural Networks}

\subsection{Cross Entropy vs Accuracy}

\begin{domanda}(Per quale motivo usiamo la cross entropy nella multi-class classification? Perché non accuracy?)
\end{domanda}

Se prendessimo un esempio di classificazione con 3 classi $1,2,3$ e due
classificatori. Immaginiamo di avere degli examples che hanno \textbf{true
    class label}:

\begin{itemize}
    \item 0 0 1
    \item 0 1 0
    \item 1 0 0
\end{itemize}

E avessimo due classificatori che hanno come risultato:

%tablella con 3 righe e 3 colonne
\begin{table}[H]
    \centering
    \textbf{Classificatore 1:}

    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Example 1} & \textbf{Example 2} & \textbf{Example 3} \\
        \hline
        0.1                & 0.1                & 0.8                \\
        \hline
        0.1                & 0.8                & 0.1                \\
        \hline
        0.4                & 0.5                & 0.1                \\
        \hline
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \textbf{Classificatore 2:}

    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Example 1} & \textbf{Example 2} & \textbf{Example 3} \\
        \hline
        0.3                & 0.3                & 0.4                \\
        \hline
        0.3                & 0.4                & 0.3                \\
        \hline
        0.4                & 0.5                & 0.1                \\
        \hline
    \end{tabular}
\end{table}


Entrambi hanno un'\textbf{accuracy} del $0.66$ ma il \textbf{classificatore 1} è
più sicuro delle sue predizioni. La \textbf{cross entropy} è una funzione che
misura la \textbf{distanza} tra due distribuzioni di probabilità. In questo caso
misura la distanza tra la distribuzione di probabilità del classificatore e la
distribuzione di probabilità delle \textbf{true class label}. La cross entropy
è definita come:

\begin{equation}
    H(p,q) = - \sum_{x} p(x) \log q(x)
\end{equation}

Dove $p$ è la distribuzione di probabilità delle \textbf{true class label} e $q$
è la distribuzione di probabilità del classificatore. 


\subsection{Workflow per image classification}


\begin{lstlisting}[language=Python, caption=Workflow per image classification]
img_size=(50,50)

images = []
age = []
gender = []
for img in os.listdir(path):
  ages = img.split("_")[0]
  
  if int(ages) <18 or int(ages)>25:
    continue
  
  genders = img.split("_")[1]
  img = cv2.imread(str(path)+"/"+str(img))
  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
  img = cv2.resize(img, img_size, interpolation = cv2.INTER_AREA)
  images.append(np.array(img))
  age.append(np.array(ages))
  gender.append(np.array(genders))

\end{lstlisting}

In questo caso, vogliamo creare un modello per classificare \textbf{gender} e \textbf{age}. Facciamo un po' di modifiche alla dimensione
delle immagini e le salviamo ciò che ci serve in un array.

\begin{lstlisting}[language=Python, caption=Workflow per image classification]
age = np.array(age,dtype=np.int64)
images = np.array(images) / 255.  
gender = np.array(gender,np.uint64)

n=9
idx_toplot = np.random.randint(len(images), size=n)
plt.figure(figsize=(10, 10))
for i in range(n):
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(images[idx_toplot[i]])
  plt.title(f'Age={age[idx_toplot[i]]}, Gender={gender[idx_toplot[i]]}')
  plt.axis('off')
\end{lstlisting}

\subsubsection{Bilanciare le classi}

Se ci sono problemi di \textbf{unbalance} tra le classi di un dataset, ciò che si può fare per bilanciare 
le classi è \textbf{aumentare} il numero di esempi della classe con meno esempi. In questo caso,
possiamo fare \textbf{data augmentation} per aumentare il numero di esempi per ogni classe che 
ha meno esempi.

\begin{lstlisting}[language=Python, caption=Data augmentation]
data_augmentation = tf.keras.Sequential(
  [
    layers.RandomFlip("horizontal",input_shape=(img_size[0],img_size[1],3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
  ]
)

# Find the class to be augmented and the major one
minor_class = min(gender_class_counts, key=gender_class_counts.get)
major_class = max(gender_class_counts, key=gender_class_counts.get)

# Select the images belonging to the class to augment
img_seeds = images[gender==minor_class]

# Select random indexes for the images to augment
n_augment = gender_class_counts[major_class]-gender_class_counts[minor_class]
idx_to_aug = np.random.randint(img_seeds.shape[0], size=n_augment)

new_images = []
new_gender = []
plt.figure(figsize=(10, 10))
for i in range(n_augment):
  augmented_image = data_augmentation(img_seeds[idx_to_aug[i]])
  new_images.append(augmented_image)
  new_gender.append(minor_class)

  if i<9:
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(augmented_image)
    plt.axis("off")
\end{lstlisting}

A questo punto, dopo aver \textbf{aumentato} il numero di esempi della classe minore, arriviamo ad avere 
un dataset bilanciato tra le due classi. Per quanto riguarda il modello, solita roba.

\begin{lstlisting}[language=Python, caption=Modello]
x_train_age, x_test_age, y_train_age, y_test_age = train_test_split(images, age, random_state=42)

x_train_gender, x_test_gender, y_train_gender, y_test_gender = train_test_split(balanced_images, balanced_gender, random_state=42)

gender_model = Sequential()

gender_model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(img_size[0],img_size[1],3)))
gender_model.add(MaxPool2D(pool_size=3, strides=2))

gender_model.add(Conv2D(64, kernel_size=3, activation='relu'))
gender_model.add(MaxPool2D(pool_size=3, strides=2))

gender_model.add(Conv2D(128, kernel_size=3, activation='relu'))
gender_model.add(MaxPool2D(pool_size=3, strides=2))

gender_model.add(Flatten())
gender_model.add(Dropout(0.2))
gender_model.add(Dense(128, activation='relu'))
gender_model.add(Dense(1, activation='sigmoid', name='gender'))

gender_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history_gender = gender_model.fit(x_train_gender, y_train_gender,
                        validation_data=(x_test_gender, y_test_gender), epochs=10)

###########################
gender_model.save(save_model_path+'gender_model.h5')
###########################

\end{lstlisting}

\begin{domanda}(Per quale motivo utilizziamo la funzione \textbf{save}?)
\end{domanda}

Perché vogliamo salvare il modello che abbiamo creato in un file. In questo caso, il modello viene salvato
in un file \textbf{.h5}. Salviamo \textbf{i pesi della rete} per poter continuare in un secondo momento
l'addestramento della rete.

\begin{osservazione}(Cosa impara la rete?)
\end{osservazione}

La parte di convoluzione CNN impara a riconoscere le \textbf{features} delle immagini. La parte di
\textbf{Dense} impara a classificare le immagini in base alle features che ha imparato la parte di convoluzione.