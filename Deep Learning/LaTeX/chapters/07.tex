\section{Serie Temporali | Time Series}
\label{sec:time-series}

Le serie temporali vengono usate in campi come la \textbf{predizione di prezzi
    di azioni}, che richiedono una conoscenza dei trend passati per funzionare. Le
reti neurali Feed Forward non considerano gli stati temporali. Si utilizza,
infatti, un'altra architettura di rete neurale: \textbf{Recurrent Network -
    RNN}

\subsection{Recurrent Neural Network RNN}

Una RNN itera sugli elementi mantenendo uno stato che contiene informazioni di
ciò che è stato visto finora. Questo stato viene passato avanti ad ogni
iterazione.

\begin{definition} RNN

\end{definition}

Una RNN è un grafo con cicli. I percettroni beneficiano del feedback dei loop.
L'output di un percettrone al tempo $t$ è coinvolto nel calcolo dell'output di
un percettrone al tempo $t+1$.

%figura da fare
\begin{figure}[H]
    \begin{center}
        \begin{tikzpicture}
            \node[draw,circle] (x) at (0,0) {$x$};
            \node[draw,rectangle] (A) at (2,0) {$A$};
            \node[draw,circle] (y) at (4,0) {$y$};
            \draw[->] (x) -- (A);
            \draw[->] (A) -- (y);
            \draw[->] (A) to [out=45,in=135,looseness=8] (A);
        \end{tikzpicture}
    \end{center}
\end{figure}

%figura da fare
\begin{figure}[H]
    \begin{center}
        \begin{tikzpicture}
            \node[draw,circle] (x) at (0,0) {$x_0$};
            \node[draw,rectangle] (A) at (0,2) {$A$};
            \node[draw,circle] (y) at (0,4) {$h_0$};
            \draw[->] (x) -- (A);
            \draw[->] (A) -- (y);
            \draw[->] (A) to [out=45,in=135,looseness=8] (A);
        \end{tikzpicture}
    \end{center}
\end{figure}

Scrivere equazione di pagina 5

Un esempio di codice è il seguente
\begin{lstlisting}[language=Python]
    Da copiar 
\end{lstlisting}

\subsubsection{L'utilizzo delle RNN}

Alla fine, tutto ciò che noi andiamo a fare è \textbf{aggiungere dei layer}
alla nostra rete.

\begin{lstlisting}[language=python]
    model.add(SimpleRNN(32, return_sequences=True))#Return a list
    model.add(SimpleRNN(32, return_sequences=True))#Return a list
    model.add(SimpleRNN(32, return_sequences=True))#Return a list
    model.add(SimpleRNN(32)) # last layer only returns last output

    model.summary()
\end{lstlisting}

Un esempio di codice di rete è:

\begin{lstlisting}[language=python]
from keras.datasets import imdb
from keras.preprocessing import sequence

max_features = 10000 # number of words to consider as features
maxlen = 500
batch_size = 32

(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)

input_train = sequence.pad_sequences(input_train, maxlen=maxlen)
input_test = sequence.pad_sequences(input_test, maxlen=maxlen)

from keras.layers import Dense

model = Sequential()
model.add(Embedding(max_features, 32))
model.add(SimpleRNN(16))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='rmsprop'
            , loss='binary_crossentropy'
            , metrics=['acc'])

history = model.fit(input_train, y_train,
            epochs=10,
            batch_size=128,
            validation_split=0.2)
\end{lstlisting}

Questo codice ha un problema: \textbf{non funziona}. Il problema è la
\textbf{back propagation} attraverso il tempo. La normale backpropagation non
funziona e ha bisogno di un cambiamento per adattarsi al \textbf{feedback
    loop}. Immaginiamo di avere una funzione del genere:
\begin{equation}
    f(f(f(f(f(f(f(f(f(f(f(f(x_0 | x_1 , \dots , x_n))))))))))))
\end{equation}

Praticamente si ha un numero di derivate ripetuto. Poi, dalle slides, dopo
tutti i calcoli si arriva ad avere un risultato in cui la derivata ha valore
che \textbf{tende sempre a 0}. Come se si trovasse sempre un minimo globale.
Quindi, questo approccio non funziona. Il \textbf{gradiente sparisce}

\textbf{Motivazione:} la sequenza è troppo lunga.
\begin{definition}(
    Spiegazione del problema )

    Il problema della dipendenza a lungo termine è una sfida nell'addestramento
    delle reti neurali artificiali, in particolare le reti neurali ricorrenti
    (RNN). Si riferisce alla difficoltà che queste reti hanno nell'apprendere a
    collegare informazioni o contesti da passaggi precedenti nella sequenza a
    passaggi successivi.

    Ad esempio, considera un modello di linguaggio che cerca di prevedere la parola
    successiva in una frase. Se la frase è "Sono cresciuto in Francia... parlo
    fluentemente ---", il modello deve ricordare il contesto della "Francia" da
    molto prima nella frase quando arriva al punto vuoto, così può riempirlo con
    "francese". Questa è una dipendenza a lungo termine.

    Le RNN fanno fatica con questo a causa del problema dei "gradienti che
    svaniscono". Durante la retropropagazione, i gradienti spesso diventano sempre
    più piccoli man mano che vengono propagati all'indietro nel tempo. Ciò
    significa che gli aggiornamenti ai pesi che collegano i passaggi precedenti
    nella sequenza a quelli successivi possono essere molto piccoli, e la rete può
    non riuscire a imparare queste dipendenze a lungo termine.
\end{definition}

Una proposta di soluzione è quella di \textbf{cambiare la funzione di
    attivazione}.

\textbf{Soluzione}: Long Short Term Memory (LSTM)

\subsection{Long Short Term Memory (LSTM)}

Queste RNN speciali sono reti capaci di risolvere il problema delle dipendenze a lungo termine. In paticolare, 
sono state progettate per \textbf{controllare la sparizione del gradiente} e \textbf{evitare proprio il problema della dipendenza a lungo termine}

rifare figura a pagina 21

Riguardo l'archiettura, parliamo di una cosa importante.

\textbf{Lo stato della cella} salva un'informazione interna della catena \textbf{Storico interno}. Questa informazione,
se rilevante, può essere \textbf{propagata}. Per controllare il flow di queste informazioni si una un \textbf{gate}. Servono, appunto, 
per decidere quali informazioni far passare.


\textbf{Ci sono formule da ricopiare}
\begin{itemize}
    \item \textbf{Forget Gate}: decide quali informazioni scartare e quali tenere
    \item \textbf{Input Gate}: decide quali informazioni passare e quanto devono influenzare lo storico interno
    \item \textbf{Aggiornamento dello stato interno}: Gate che risolvono il problema della dipendenza a lungo termine e del gradiente che svanisce
    \item \textbf{Output Gate}: L'output dipende dallo stato interno della cella. La LSTM controlla quanto l'output deve essere influenzato dallo storico interno
\end{itemize}

\begin{lstlisting}[language=python]
from keras.layers import LSTM

model = Sequential()
model.add(Embedding(max_features, 32))
model.add(LSTM(32))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='rmsprop'
            ,loss='binary_crossentropy'
            ,metrics=['acc'])

            history = model.fit(input_train, y_train,
epochs=10,
batch_size=128,
validation_split=0.2)
\end{lstlisting}

\newpage