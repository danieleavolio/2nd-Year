\section{Ottimizzazione senza vincoli}


$$
2x_1^3 - 3x_1^2 -6x_1^2x_2 +6x_1x_2^2 +6x_1x_2
$$

Calcoliamo il gradiente e la matrice hessiana

$$
\nabla f(x) = \begin{bmatrix}
6x_1^2 - 6x_1 - 12x_1x_2 + 6x_2^2 + 6x_2 \\
-6x_1^2 + 6x_1^2 + 12x_1x_2 + 6x_1 
\end{bmatrix}
$$

Ora calcoliamo la matrice hessiana

$$
\nabla^2 f(x) = \begin{bmatrix}
12x_1 - 6 - 12x_2 & -12x_1 + 12x_2 + 6 \\
-12x_1 + 12x_2 + 6 & 12x_1
\end{bmatrix}
$$

Spieghiamo i passaggi per il calcolo della Hessiana

$$
\frac{\partial^2 f}{\partial x_1^2} = 12x_1 - 6 - 12x_2
$$

$$
\frac{\partial^2 f}{\partial x_1 \partial x_2} = -12x_1 + 12x_2 + 6
$$

Qui il $-12x_1 + 12x_2 + 6$ viene fuori dal seguente passaggio

In parole povere, prima si calcola la derivata parziale di f rispetto a x1, e poi si calcola la derivata di quel risultato rispetto a x2.
$$
f(x1, x2) = 2x1^3 - 3x1^2x2 + 6x1x2^2 + x2^2 + 6x1x2
$$

$$
= 6x1^2 - 6x1x2 + 6x2^2 + 6x2
$$

$$
= -12x1 + 12x2 + 6
$$


$$
\frac{\partial^2 f}{\partial x_2 \partial x_1} = -12x_1 + 12x_2 + 6
$$

$$
\frac{\partial^2 f}{\partial x_2^2} = 12x_1
$$

Quindi, per spiegare ocme funziona.

Data una funzione, bisogna calcolare inizialmente il \textbf{gradiente}.

Applicando la \textbf{condizione necessaria di primo ordine} troviamo i punti stazionari, ovvero quelli in 
cui il $\nabla f(x) = 0$. Cioé, calcoli il gradiente e lo poni uguale a zero.

Ponendo il gradiente uguale a zero bisogna risolvere il sistema di equazioni per trovare 
i possibili punti stazionari. Una volta trovati, nel nostro esempio erano $4$, 
bisogna esaminare i punti utilizzando la \textbf{condizione sufficiente di secondo ordine} e \textbf{la condizione necessaria di secondo ordine}.

Per farlo, si calcola l'Hessiana della funzione \textbf{in un punto}, per ogni punto. Ricorda bene 
come si calcola l'Hessiana, sopratutto quando compaiono due variabili.

Dopo aver calcolato l'hessiana e sostituito con il punto, 
bisogna \textbf{porre} il determinante della hessiana moltiplicata per l'identità con $\lambda$ uguale a zero.

Calcolando il determinante e ponendolo uguale a zero si risolve l'equazione per trovare gli autovalori $\lambda$. In base 
al segno degli autovalori si può dire il "segno", della matrice. Controllando le 
condizioni necessarie e sufficienti di secondo ordine si può dire se il punto è un minimo locale, minimo locale stretto, massimo locale, massimo locale stretto, o punto sella.

\section{Ottimizzazione con vincoli}
In Ottimizzazione con vincoli abbiamo due tipi di vincoli:
\begin{itemize}
    \item Uguaglianza - $g(x) = 0$ - E
    \item Disuguaglianza - $g(x) \geq 0$ - I
\end{itemize}

\textbf{Nota sui programmi quadratici}: Se la funzione obiettivo è del tipo $f(x) = \frac{1}{2}x^TMx+c^Tx$, con $M$ una matrice simmetrica
che significa che $M = M^T$, e tutti i vincoli $g_i$ sono funzioni lineari (sia di Uguaglianza che di Disuguaglianza), allora il problema è un \textbf{programma quadratico}.

Se invece la funzione è $f(x) = c^Tx$, il problema quadratico diventa un programma lineare.

\begin{definition}
    (Vincoli attivo)

    Dato un punto $\bar{x} \in X$, un vincolo $g_i(\bar{x}) = 0$ si dice \textbf{vincolo attivo}.
    
    \textbf{Nota:} Indichiamo $\mathcal{A}(\bar{x})$ l'insieme dei vincoli attivi in $\bar{x}$.
\end{definition}

\subsection{KKT Conditions}
Sono condizioni di ottimalità di primo ordinep per i programmi con vincoli. 

Vediamo in particolare cosa ci interessa:

\begin{definition}
    (LICQ - Linear Independence Constraint Qualification)

    Dato un punto $\bar{x} \in X$, LICQ regge in $\bar{x}$ se l'insieme $\{\nabla g_i(\bar{x}), i \in \mathcal{A}(\bar{x})\}$ 
    cioè l'insieme dei vincoli attivi per $\bar{x}$, deve essere costituito solamente da vettori linearmente indipendenti.
\end{definition}

\begin{definition}
    (Funzione Lagrangiana)

    Dato uno vettore $\lambda \in R^{|E|+|I|}$ chiamato vettore dei moltiplicatori Lagrangiani, diciamo che la funzione lagrangiana di $P$ è:

    $$
    \mathcal{L}(x,\lambda) = f(x) - \sum_{i \in E} \lambda_i g_i(x) - \sum_{i \in I} \lambda_i g_i(x)   
    $$
    con $\lambda \geq 0 \ \forall i \in I$. 
\end{definition}

Se vogliamo fare un esempio, ecco la spiegazione di come si lavora.

Data una regione ammissibile, quindi un insieme di vincoli, analizziamo prendendo un punto $\bar{x}$
come si comportano i vincoli.

Controlliamo quali sono i vincoli che si attivano, ovvero quando la funzione $g_i(\bar{x}) = 0$.

Prendiamo questi vincoli e calcoliamo il gradiente del vincolo, ovvero $\nabla g_i(\bar{x})$.
Se abbiamo ancora delle variabili dopo aver fatto il gradiente, sostituiamo alla $x$ che 
compare nel gradiente il punto $\bar{x}$.

Poi, dopo aver calcolato questi valori, inseriamo tutti i gradienti in una matrice, chiamata $B$. 
Bisogna controllare che i gradienti siano linearmente indipendenti, e per comodità
possiamo calcolare il \textbf{determinante} della matrice e controllare che sia $\neq 0$.

Se ad occhio si vede che dei gradienti sono linearmente dipendenti, allora si può dire 
direttamente che $LICQ$ non reggono.

\subsection{Teoremi delle KKT Conditions}

Ci sono delle condizioni da rispettare:

Sia $x^*$ un minimo locale per il problema $P$ e che le LICQ reggono. Allora possiamo dire che 
$\exists \lambda^*$ tale che:
$$
KKT-Conditions = \begin{cases}
    \nabla_x \mathcal{L}(x^*, \lambda^*) & = 0 \\
    g_i(x^*) & = 0 \ \forall i \in E \\
    g_i(x^*) & \geq 0 \ \forall i \in I \\
    \lambda_i^* & \geq 0 \ \forall i \in I \\
    \lambda_i^* g_i(x^*) & = 0 \ \forall i \in E \cup I \\
\end{cases}
$$

Una nota, che non sappiamo a cosa serve ma è importante.

$$
\mathcal{L}(x, \lambda) = f(x) - \sum_{i \in E} \lambda_i g_i(x) - \sum_{i \in I} \lambda_i g_i(x)
$$
Questa formula ci dice che la funzione lagrangiana è la funzione obiettivo meno la sommatoria dei vincoli moltiplicati per i moltiplicatori lagrangiani.

Quando applichiamo il gradiente rispetto ad $x$:

$$
\nabla_x \mathcal{L}(x^*, \lambda^*) = \nabla f(x^*) - \sum_{i \in E} \lambda_i^* \nabla g_i(x^*) - \sum_{i \in I} \lambda_i^* \nabla g_i(x^*)
$$

Ora, \textbf{nota} importante: Se $g_i(x^*) = 0$, allora serve che $\lambda^*=0$, questo torna utile 
per l'ultima condizione di prima, ovvero $\lambda_i^* g_i(x^*) = 0 \ \forall i \in E \cup I$.
Perché questo implica che:

\begin{equation}
    \begin{aligned}
        \implies \nabla_x \mathcal{L}(x^*, \lambda^*) & = \nabla f(x^*) - \sum_{i \in \mathcal{A}(x^*)} \lambda_i^* \nabla g_i(x^*) = 0 \\
        \implies \nabla f(x^*) & = \sum_{i \in \mathcal{A}(x^*)} \lambda_i^* \nabla g_i(x^*) \\
    \end{aligned}
\end{equation}

In questo modo possiamo trovare il valore dei $\lambda_i^*$.

Solitamente, quando si lavora con un esempio, possiamo avere\textit{ diversi punti.} Si parte \textbf{verificando le LICQ} e, successivamente,
si verificano le \textbf{KKT Conditions}. Partiamo dalle LICQ perché le KKT conditions 
hanno bisogno di avere le LICQ che reggono per quel punto per trovare il $\lambda^*$.

Per le \textbf{LICQ}:

Dato un punto controlliamo quali sono i vincol vincoli $g_i(x) \in \mathcal{A}(x)$ che si attivano, ovvero quando la funzione $g_i(x) = 0$.
Trovato questo insieme si calcola il gradiente per ogni vincolo attivo. Successivamente si controlla che i vincoli siano 
linearmente indipendenti tra loro e, se lo sono, allora le LICQ reggono.

Per le \textbf{KKT Conditions}:
Si calcola inizialmente la funzione lagrangiana. Questo è dato dalla formula che abbiamo visto prima, con 
la funzione obiettivo meno la sommatoria dei vincoli moltiplicati per i moltiplicatori lagrangiani.

Successivamente calcoliamo il gradiente della funzione lagrangiana rispetto ad $x$ e lo poniamo uguale a zero. Ci ritroveremo 
ad avere un sistema di equazioni con $\lambda_i$ come incognita. Per trovare il valore di $\lambda_i$ bisogna
risolvere il sistema di equazioni.

Dopo aver trovato il valore di $\lambda^*$ si controlla che ogni valore di $\lambda_i^*$ sia maggiore o uguale a zero, 
solamente per i vincoli di disuguaglianza.

\textbf{Nota importante per tanti $\lambda$}: Se in una regione ammissibile abbiamo tanti vincoli, 
il $\lambda^*$ da trovare avrà tanti valori quanti i vincoli. Abbiamo però modo di semplificare 
il calcolo di questi. Per la proprietà della \textbf{complementarietà} abbiamo che:
$$\lambda_i * g_i(x^*) = 0 \ \forall i \in E \cup I$$. Ora, se sappiamo già che 
$g_i(x^*) >0$, allora $\lambda_i^*$ deve \textbf{PER FORZA} essere uguale a zero. 

Ad esempio, se su $5$ vincoli solo $2$ sono attivi, al calcolo della funzione lagrangiana
avremo $5$ moltiplicatori lagrangiani, ma solamente $2$ saranno diversi da zero perché
i restanti $3$ vincoli non sono attivi. Possiamo rimuovere dall'equazione per 
semplificare i calcoli. 

\textbf{Implicazione diretta}: Se le LCIQ reggono:

\begin{itemize}
    \item $x^*$ è un minimo locale $\implies$ le KKT Reggono
    \item Se le KKT non reggono $\implies$ $x^*$ non è un minimo locale
\end{itemize}

Notiamo che le KKT sono \textbf{condizioni necessarie} ma non sufficienti.

\newpage

\section{Approcci di soluzione}

Quando partiamo da un punto iniziale $x^{0}$ possiamo avere più casi di problemi.
\begin{itemize}
    \item Caso senza vincoli $\rightarrow \in R^n$
    \item Caso con vincoli. Questo caso si divide in due:
    \begin{itemize}
        \item $x$ potrebbe non appartenere alla regione ammissibile $x \notin X$
        \item $x$ appartiene alla regione ammissibile $x \in X$
    \end{itemize}
\end{itemize}

\begin{domanda}
    Quando cerchiamo un nuovo punto, quando ci fermiamo?

    Questo dipende dal tipo di problema che stiamo risolvendo. 

    \begin{itemize}
        \item Caso senza vincoli: Ci fermiamo quando troviamo un punto stazionario, ovvero quando 
        dato un punto $x$, il gradiente della funzione nel punto è uguale a 0 $\nabla f(x) = 0$.
        \item Caso con vincoli: Ci fermiamo quando troviamo un punto che soddisfa le KKT Conditions.
    \end{itemize}
\end{domanda}

Abbiamo due metodi di soluzione: \textbf{Metodi di ricerca lineari} che possonoe essere a loro volta \textbf{esatti} e \textbf{inesatti},
oppure il \textbf{Metodo della regione di confidenza}.

\begin{definition}
    Metodi di ricerca lineari

    Un nuovo punto $x^{k+1}$ viene calcolato usando $x^k + \alpha_k d^k$, con $\alpha_k$
    un passo di ricerca e $d^k$ una direzione di ricerca.

    Nota: $\alpha \in R > 0$ e $d \in R^n$.

    Ad esempio, il \textit{simplesso} è un metodo di ricerca lineare.
\end{definition}

\begin{domanda}
    Qual è la differenza tra esatto e inesatto?

    Il calcolo del nuovo punto $x^{k+1}$ può essere esatto o inesatto. Se è esatto, è risolto esattamente,
    se è inesatto è calcolato in modo approssimato.
\end{domanda}

\begin{definition}
    Regione di confidenza

    In quesot metodo un nuovo punto $x^{k+1}$ è calcolato usando il vecchio punto e una direzione.

    La direzione $d^k$ è calcolata risolvendo un sotto problema del tipo:

    $$
    P_{TR} = \begin{cases}
        \min_{d} m_k(x^k + d^k) \\
        x^k + d \in X
    \end{cases}
    $$

    Dove si indica con $m_k$ la funzione modello.

    Quando si approssima per $d$, diciamo che è approssimata bene se la 
    la differenza tra la funzione originale e la funzione modello, nel punto nuovo calcolato 
    è bassa. Altrimenti, è una cattiva approssimazione.
\end{definition}


\begin{definition}
    Norma di un vettore

    Si indica con norma del vettore un mapping tra $R^n \rightarrow R^+$ che soddisfa le seguenti proprietà:
    \begin{itemize}
        \item $||x|| = 0 \iff \vec{x} = 0$
        \item $||\vec{x}+\vec{y}|| \leq ||\vec{x}|| + ||\vec{y}|| \ \forall x,y \in R^n$
        \item $||\alpha \vec{x}|| = |\alpha| ||\vec{x}|| \ \forall \alpha \in r \land x \in R^n$
    \end{itemize}
\end{definition}

Ci sono varie norme, ma a noi interessa la norma $L_2$

$$
||x||_2 = \sqrt{\sum_{i=1}^n x_i^2}
$$

\textbf{Nota:} Se $x \in R$, allora $||x|| = |x|$.

\textbf{Nota 2:} La norma non è differenziabile perché la radice quadrata non è differenziabile in $0$.

\textbf{Nota 3:} Possiamo scrivere $||x||_2^2 = x^Tx$.


\subsection*{Caso senza vincoli}

$$
P = \begin{cases}
    \min{x}  f(x)\\
    f:R^n  \rightarrow R\\
    f  \in C^2
\end{cases}
$$

\begin{definition}
    (Direzione di discesa)

    Dato un $\bar{x} \in R^n$, il vettore $\bar{d}$ è una direzione di discesa di $f$ al
    punto $\bar{x}$ se esiste un $\bar{\alpha} > 0$ tale che:

    $$f(\bar{x} + \alpha \bar{d}) < f(\bar{x}) \ \forall \alpha \in (0, \bar{\alpha})$$

    \textbf{Nota:} Se questa $\bar{d}$ essiste e $\nabla f(\bar{x})^T \bar{d} < 0$, allora la direzione è una direzione di discesa. Se 
    siamo nel caso in cui $f$ è convessa, allora l'inverso è vero.
    $$\nabla f(\bar{x})^T \bar{d} < 0 \iff \bar{d} \text{ è una direzione di discesa}$$
\end{definition}

\begin{definition}
    (Direzione di steepest descent)

    Dal teorema di Taylor sappiamo che possiamo approssimare $f(x^k + d)$ con $f(x^k) + \nabla f(x^k)^T d$. 
    Vogliamo $minimizzare$ questa approssimazione, per $d$.

    $$
    P_K = \begin{cases}
        \min_{d} \cancel{f(x^k)} + \nabla f(x^k)^T d \\
        \frac{1}{2}||d||_2^2 = \frac{1}{2}
    \end{cases}
    $$

    Ma la prima parte possiamo semplificare perché non compare la $d$.

    Il nostro obiettivo è trovare $d$. Come facciamo? Possiamo usare il metodo dei moltiplicatori lagrangiani.

    $$
    \mathcal{L}(d, \lambda) = \nabla f(x^k)^T d - \lambda(\frac{1}{2}||d||_2^2 - \frac{1}{2}) 
    $$

    $$\nabla_{d} \mathcal{L}(d, \lambda) = \nabla f(x^k) - \lambda d = 0$$

    $$\nabla f(x^k) = \lambda d$$

    Si assume che $\lambda \neq 0$ perché se fosse zero, allora $\nabla f(x^k) = 0$ e quindi
    $x^k$ sarebbe un punto stazionario.

    $$d = \frac{\nabla f(x^k)}{\lambda}$$

    Ora, dal vincolo sappiamo che $||d||^2 = 1$, quindi:
    $$\frac{||\nabla f(x^k)||^2}{\lambda^2} = 1$$

    Da qui troviamo i moltiplicatori lagrangiani. 

    $$\lambda^2 = ||\nabla f(x^k)||^2 \rightarrow \lambda = \pm ||\nabla f(x^k)||$$
    
    Siccome siamo in un contesto di minimizzazione, prendiamo il valore negativo.

    $$d^* = -\frac{\nabla f(x^k)}{||\nabla f(x^k)||}$$


    \textbf{Nota:} $\nabla f(x^k)^T d^*$ = $\frac{-\nabla f(x^k)^T \nabla f(x^k)}{||\nabla f(x^k)||} = -||\nabla f(x^k)|| < 0$.

\end{definition}

Quando hai un esempio svolto, per capire se effettivamente la \textbf{step size} cioé $\alpha$ è buono, 
controlli se effettivamente il nuovo punto ha un valore inferiore.

$$ 
f(x^k + \alpha d^k) < f(x^k)
$$

\begin{definition}
    Metodo di Newton

    Il problema è sempre del tipo:

    $$
    P = \begin{cases}
        \min_{x} f(x) \\
        f: R^n \rightarrow R \\
        f \in C^2
    \end{cases}
    $$

    Sempre dal teorema di Taylor, possiamo approssimare:
    $$
    f(x^k + d) \approx f(x^k) + \nabla f(x^k)^T d + \frac{1}{2} d^T \nabla^2 f(x^k) d
    $$

    Assumiamo che $\nabla^2 f(x^k)$ sia definita positiva.

    Il problema che vogliamo risolvere è:

    $$
    P_K = \begin{cases}
        \min_{d} m_k(d)\\
    \end{cases}
    $$

    Risolviamo il problema:

    $$\nabla_d m_k(d) = \nabla f(x^k) + \nabla^2 f(x^k) d = 0$$
    
    $$\nabla f(x^k) = - \nabla^2 f(x^k) d$$ che è positiva definita 

    $$d = -(\nabla^2 f(x^k))^{-1} \nabla f(x^k)$$ che è la direzione di Newton

    $$\nabla f(x^k)^T d = \nabla f(x^k)^T [ -\nabla^2 f(x^k)]^{-1} \nabla f(x^k)$$

    $$=-\nabla f(x^k)^T  \nabla^2 f(x^k)^{-1} \nabla f(x^k) < 0$$ è una direzione di discesa

    \textbf{Nota:} La parte interna senza il $-$ deve essere $>0$

    \textbf{Note 2:}
    \begin{itemize}
        \item $m_k(0) = f(x^k)$
        \item $\nabla m_k(0) = \nabla f(x^k)$
        \item $\nabla^2 m_k(0) = \nabla^2 f(x^k)$
    \end{itemize}
\end{definition}


\newpage